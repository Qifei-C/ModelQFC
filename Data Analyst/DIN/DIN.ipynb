{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GAR6Gu6gV4-2"
   },
   "outputs": [],
   "source": [
    "#!pip install -U pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xt9UIiY_LXtr"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW, SGD\n",
    "from torch.optim.lr_scheduler import LinearLR\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1sdS0uKvLx3W"
   },
   "outputs": [],
   "source": [
    "from din import DIN\n",
    "from data import DINDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "z5dRNAsVWr-F"
   },
   "outputs": [],
   "source": [
    "class PLModel(pl.LightningModule):\n",
    "    def __init__(self, device='cpu'):\n",
    "        super().__init__()\n",
    "        self._device = device\n",
    "        self.model = DIN(device=device)\n",
    "\n",
    "    def forward(self, user, trg_movie, trg_genre, hist_movie, hist_genre, mask_id):\n",
    "        return self.model(user, trg_movie, trg_genre, hist_movie, hist_genre, mask_id)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        user, trg_movie, trg_genre, hist_movie, hist_genre, mask_id, label = map(lambda x:x.to(self._device), batch)\n",
    "        outputs = self(user, trg_movie, trg_genre, hist_movie, hist_genre, mask_id)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loss = criterion(outputs, label)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        user, trg_movie, trg_genre, hist_movie, hist_genre, mask_id, label = map(lambda x:x.to(self._device), batch)\n",
    "        outputs = self(user, trg_movie, trg_genre, hist_movie, hist_genre, mask_id)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loss = criterion(outputs, label)\n",
    "        prob = torch.softmax(outputs, dim=-1)\n",
    "        pred = torch.argmax(prob, dim=-1)\n",
    "        accuracy = (pred == label).sum().item() / label.size(0)\n",
    "        metrics = {\n",
    "            'val_loss': loss,\n",
    "            'val_accuracy': accuracy\n",
    "        }\n",
    "        self.log_dict(metrics, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        user, trg_movie, trg_genre, hist_movie, hist_genre, mask_id, label = map(lambda x:x.to(self._device), batch)\n",
    "        outputs = self(user, trg_movie, trg_genre, hist_movie, hist_genre, mask_id)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loss = criterion(outputs, label)\n",
    "        prob = torch.softmax(outputs, dim=-1)\n",
    "        pred = torch.argmax(prob, dim=-1)\n",
    "        accuracy = (pred == label).sum().item() / label.size(0)\n",
    "        metrics = {\n",
    "            'test_loss': loss,\n",
    "            'test_accuracy': accuracy\n",
    "        }\n",
    "        self.log_dict(metrics)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), lr=1e-2)\n",
    "        scheduler = LinearLR(optimizer)\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ss0g8yqqZ_cn"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "train_ds = DINDataset(\"./data/train.pkl\")\n",
    "val_ds = DINDataset(\"./data/test.pkl\")\n",
    "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=128)\n",
    "\n",
    "din = PLModel('mps')\n",
    "trainer = pl.Trainer(accelerator='cpu', \n",
    "                     devices=1, \n",
    "                     callbacks=[EarlyStopping(monitor='val_loss', mode='min')],\n",
    "                     min_epochs=5,\n",
    "                     max_epochs=20,\n",
    "                     gradient_clip_val=1.0\n",
    "                     )\n",
    "trainer.fit(din, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yBuqzSFYHBv_"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir=lightning_logs/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP4L4VHyp/FpNnYLTGZcGVi",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "mount_file_id": "17j4ukUeuy_dS1wEDVyM_5VCGmbIoUAwg",
   "name": "DIN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
